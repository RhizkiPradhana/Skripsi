{"cells":[{"cell_type":"markdown","metadata":{},"source":["**Sentiment Analysis for Twitter using Indonesian Language**\n","\n","Sentiment Analisis pada Twitter menggunakan bahasa Indonesia\n","\n","We can use LSTM for training model"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T00:53:57.689949Z","iopub.status.busy":"2022-03-25T00:53:57.688893Z","iopub.status.idle":"2022-03-25T00:54:10.155457Z","shell.execute_reply":"2022-03-25T00:54:10.154145Z","shell.execute_reply.started":"2022-03-25T00:53:57.689721Z"},"trusted":true},"outputs":[],"source":["# Import some libraries\n","\n","import pandas as pd\n","pd.options.mode.chained_assignment = None\n","import numpy as np\n","seed = 0\n","np.random.seed(seed)\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set(style = 'whitegrid')\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  ERROR: Error [WinError 2] The system cannot find the file specified while executing command git version\n","ERROR: Cannot find command 'git' - do you have 'git' installed and in your PATH?\n"]},{"name":"stdout","output_type":"stream","text":["Collecting twint\n","  Cloning https://github.com/twintproject/twint.git (to revision origin/master) to c:\\users\\user\\appdata\\local\\temp\\pip-install-qj42nnyk\\twint_3c6930876ff64c87ac84e267b1699bb7\n","Requirement already satisfied: PySastrawi in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.2.0)\n"]},{"ename":"ModuleNotFoundError","evalue":"No module named 'wordcloud'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32mc:\\xampp\\htdocs\\Github\\Skripsi\\sentiment-analysis-twitter-indonesia-97acad.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/xampp/htdocs/Github/Skripsi/sentiment-analysis-twitter-indonesia-97acad.ipynb#ch0000037?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mSastrawi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mStemmer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mStemmerFactory\u001b[39;00m \u001b[39mimport\u001b[39;00m StemmerFactory\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/xampp/htdocs/Github/Skripsi/sentiment-analysis-twitter-indonesia-97acad.ipynb#ch0000037?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mSastrawi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mStopWordRemover\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mStopWordRemoverFactory\u001b[39;00m \u001b[39mimport\u001b[39;00m StopWordRemoverFactory\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/xampp/htdocs/Github/Skripsi/sentiment-analysis-twitter-indonesia-97acad.ipynb#ch0000037?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mwordcloud\u001b[39;00m \u001b[39mimport\u001b[39;00m WordCloud\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/xampp/htdocs/Github/Skripsi/sentiment-analysis-twitter-indonesia-97acad.ipynb#ch0000037?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext\u001b[39;00m \u001b[39mimport\u001b[39;00m Tokenizer\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/xampp/htdocs/Github/Skripsi/sentiment-analysis-twitter-indonesia-97acad.ipynb#ch0000037?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequence\u001b[39;00m \u001b[39mimport\u001b[39;00m pad_sequences\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"]}],"source":["!pip3 install --user --upgrade git+https://github.com/twintproject/twint.git@origin/master#egg=twint\n","import twint\n","import nest_asyncio\n","nest_asyncio.apply()\n","\n","\n","import datetime as dt\n","import re\n","import string\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","!pip3 install PySastrawi\n","from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n","from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n","from wordcloud import WordCloud\n","\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Dense, Dropout, LSTM\n","from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.model_selection import GridSearchCV\n","from mlxtend.plotting import plot_confusion_matrix\n","from sklearn.metrics import confusion_matrix"]},{"cell_type":"markdown","metadata":{},"source":["# Proses mengambil data dari twitter "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T00:33:50.147837Z","iopub.status.busy":"2022-03-25T00:33:50.147078Z","iopub.status.idle":"2022-03-25T00:35:30.827714Z","shell.execute_reply":"2022-03-25T00:35:30.827039Z","shell.execute_reply.started":"2022-03-25T00:33:50.147801Z"},"trusted":true},"outputs":[],"source":["# Scraping 25000 tweets and then store to csv file using twint (https://github.com/twintproject/twint)\n","\n","c = twint.Config()\n","c.Search = '\"Italy\" lang:id'\n","c.Limit = 5000\n","c.Store_csv = True\n","c.Output = 'tweet_data.csv'\n","twint.run.Search(c)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-19T23:07:21.910039Z","iopub.status.busy":"2022-03-19T23:07:21.909265Z","iopub.status.idle":"2022-03-19T23:07:22.604869Z","shell.execute_reply":"2022-03-19T23:07:22.603997Z","shell.execute_reply.started":"2022-03-19T23:07:21.910002Z"},"trusted":true},"outputs":[],"source":["ls"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T00:36:00.678709Z","iopub.status.busy":"2022-03-25T00:36:00.678442Z","iopub.status.idle":"2022-03-25T00:36:00.75134Z","shell.execute_reply":"2022-03-25T00:36:00.750441Z","shell.execute_reply.started":"2022-03-25T00:36:00.678682Z"},"trusted":true},"outputs":[],"source":["# Load data from a CSV file into pandas DataFrame\n","\n","tweets_data = pd.read_csv('/kaggle/working/tweet_data.csv')\n","tweets = tweets_data[['id', 'username', 'created_at', 'tweet', 'replies_count', 'retweets_count', 'likes_count']]\n","tweets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T00:36:17.216127Z","iopub.status.busy":"2022-03-25T00:36:17.215854Z","iopub.status.idle":"2022-03-25T00:36:17.226622Z","shell.execute_reply":"2022-03-25T00:36:17.225839Z","shell.execute_reply.started":"2022-03-25T00:36:17.216097Z"},"trusted":true},"outputs":[],"source":["# Some functions for preprocessing text\n","\n","def cleaningText(text):\n","    text = re.sub(r'@[A-Za-z0-9]+', '', text) # remove mentions\n","    text = re.sub(r'#[A-Za-z0-9]+', '', text) # remove hashtag\n","    text = re.sub(r'RT[\\s]', '', text) # remove RT\n","    text = re.sub(r\"http\\S+\", '', text) # remove link\n","    text = re.sub(r'[0-9]+', '', text) # remove numbers\n","\n","    text = text.replace('\\n', ' ') # replace new line into space\n","    text = text.translate(str.maketrans('', '', string.punctuation)) # remove all punctuations\n","    text = text.strip(' ') # remove characters space from both left and right text\n","    return text\n","\n","def casefoldingText(text): # Converting all the characters in a text into lower case\n","    text = text.lower() \n","    return text\n","\n","def tokenizingText(text): # Tokenizing or splitting a string, text into a list of tokens\n","    text = word_tokenize(text) \n","    return text\n","\n","def filteringText(text): # Remove stopwors in a text\n","    listStopwords = set(stopwords.words('indonesian'))\n","    filtered = []\n","    for txt in text:\n","        if txt not in listStopwords:\n","            filtered.append(txt)\n","    text = filtered \n","    return text\n","\n","def stemmingText(text): # Reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words\n","    factory = StemmerFactory()\n","    stemmer = factory.create_stemmer()\n","    text = [stemmer.stem(word) for word in text]\n","    return text\n","\n","def toSentence(list_words): # Convert list of words into sentence\n","    sentence = ' '.join(word for word in list_words)\n","    return sentence"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T00:36:29.339627Z","iopub.status.busy":"2022-03-25T00:36:29.339375Z","iopub.status.idle":"2022-03-25T00:36:59.797059Z","shell.execute_reply":"2022-03-25T00:36:59.796334Z","shell.execute_reply.started":"2022-03-25T00:36:29.3396Z"},"trusted":true},"outputs":[],"source":["# Preprocessing tweets data\n","\n","tweets['text_clean'] = tweets['tweet'].apply(cleaningText)\n","tweets['text_clean'] = tweets['text_clean'].apply(casefoldingText)\n","tweets.drop(['tweet'], axis = 1, inplace = True)\n","\n","tweets['text_preprocessed'] = tweets['text_clean'].apply(tokenizingText)\n","tweets['text_preprocessed'] = tweets['text_preprocessed'].apply(filteringText)\n","tweets['text_preprocessed'] = tweets['text_preprocessed'].apply(stemmingText)\n","\n","# drop duplicates/spams tweets\n","tweets.drop_duplicates(subset = 'text_clean', inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T00:37:03.56401Z","iopub.status.busy":"2022-03-25T00:37:03.563745Z","iopub.status.idle":"2022-03-25T00:37:03.630949Z","shell.execute_reply":"2022-03-25T00:37:03.630162Z","shell.execute_reply.started":"2022-03-25T00:37:03.563981Z"},"trusted":true},"outputs":[],"source":["# Export to csv file\n","tweets.to_csv(r'tweet_data_clean.csv', index = False, header = True,index_label=None)\n","\n","tweets"]},{"cell_type":"markdown","metadata":{},"source":["## Determine Sentiment Polarity of Tweets with Indonesia Sentiment Lexicon"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T00:37:22.760089Z","iopub.status.busy":"2022-03-25T00:37:22.759828Z","iopub.status.idle":"2022-03-25T00:37:22.783329Z","shell.execute_reply":"2022-03-25T00:37:22.782319Z","shell.execute_reply.started":"2022-03-25T00:37:22.76006Z"},"trusted":true},"outputs":[],"source":["# Determine sentiment polarity of tweets using indonesia sentiment lexicon (source : https://github.com/fajri91/InSet)\n","\n","# Loads lexicon positive and negative data\n","lexicon_positive = dict()\n","import csv\n","with open('../input/lexicon/lexicon_positive.csv', 'r') as csvfile:\n","    reader = csv.reader(csvfile, delimiter=',')\n","    for row in reader:\n","        lexicon_positive[row[0]] = int(row[1])\n","\n","lexicon_negative = dict()\n","import csv\n","with open('../input/lexicon/lexicon_negative.csv', 'r') as csvfile:\n","    reader = csv.reader(csvfile, delimiter=',')\n","    for row in reader:\n","        lexicon_negative[row[0]] = int(row[1])\n","        \n","# Function to determine sentiment polarity of tweets        \n","def sentiment_analysis_lexicon_indonesia(text):\n","    #for word in text:\n","    score = 0\n","    for word in text:\n","        if (word in lexicon_positive):\n","            score = score + lexicon_positive[word]\n","    for word in text:\n","        if (word in lexicon_negative):\n","            score = score + lexicon_negative[word]\n","    polarity=''\n","    if (score > 0):\n","        polarity = 'positive'\n","    elif (score < 0):\n","        polarity = 'negative'\n","    else:\n","        polarity = 'neutral'\n","    return score, polarity"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T00:37:28.770265Z","iopub.status.busy":"2022-03-25T00:37:28.769992Z","iopub.status.idle":"2022-03-25T00:37:28.85483Z","shell.execute_reply":"2022-03-25T00:37:28.854141Z","shell.execute_reply.started":"2022-03-25T00:37:28.770235Z"},"trusted":true},"outputs":[],"source":["# Results from determine sentiment polarity of tweets\n","\n","results = tweets['text_preprocessed'].apply(sentiment_analysis_lexicon_indonesia)\n","results = list(zip(*results))\n","tweets['polarity_score'] = results[0]\n","tweets['polarity'] = results[1]\n","print(tweets['polarity'].value_counts())\n","\n","# Export to csv file\n","tweets.to_csv(r'tweets_data_clean_polarity.csv', index = False, header = True,index_label=None)\n","\n","tweets"]},{"cell_type":"markdown","metadata":{},"source":["## Analysis and Visualization"]},{"cell_type":"markdown","metadata":{},"source":["## Comparasion Sentiment Polarity on Tweets Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T00:37:53.765838Z","iopub.status.busy":"2022-03-25T00:37:53.765571Z","iopub.status.idle":"2022-03-25T00:37:53.92385Z","shell.execute_reply":"2022-03-25T00:37:53.923207Z","shell.execute_reply.started":"2022-03-25T00:37:53.765808Z"},"trusted":true},"outputs":[],"source":["fig, ax = plt.subplots(figsize = (6, 6))\n","sizes = [count for count in tweets['polarity'].value_counts()]\n","labels = list(tweets['polarity'].value_counts().index)\n","explode = (0.1, 0, 0)\n","ax.pie(x = sizes, labels = labels, autopct = '%1.1f%%', explode = explode, textprops={'fontsize': 14})\n","ax.set_title('Sentiment Polarity on Tweets Data \\n (total = 23699 tweets)', fontsize = 16, pad = 20)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Top 10 Positive and Negative Tweet Sentiments"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T00:37:58.899625Z","iopub.status.busy":"2022-03-25T00:37:58.899035Z","iopub.status.idle":"2022-03-25T00:37:58.918207Z","shell.execute_reply":"2022-03-25T00:37:58.917453Z","shell.execute_reply.started":"2022-03-25T00:37:58.899586Z"},"trusted":true},"outputs":[],"source":["pd.set_option('display.max_colwidth', 3000)\n","positive_tweets = tweets[tweets['polarity'] == 'positive']\n","positive_tweets = positive_tweets[['text_clean', 'polarity_score', 'polarity']].sort_values(by = 'polarity_score', ascending=False).reset_index(drop = True)\n","positive_tweets.index += 1\n","positive_tweets[0:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T00:38:09.325623Z","iopub.status.busy":"2022-03-25T00:38:09.325126Z","iopub.status.idle":"2022-03-25T00:38:09.341923Z","shell.execute_reply":"2022-03-25T00:38:09.341232Z","shell.execute_reply.started":"2022-03-25T00:38:09.325586Z"},"trusted":true},"outputs":[],"source":["pd.set_option('display.max_colwidth', 3000)\n","negative_tweets = tweets[tweets['polarity'] == 'negative']\n","negative_tweets = negative_tweets[['text_clean', 'polarity_score', 'polarity']].sort_values(by = 'polarity_score', ascending=True)[0:10].reset_index(drop = True)\n","negative_tweets.index += 1\n","negative_tweets[0:10]"]},{"cell_type":"markdown","metadata":{},"source":["## Word Cloud"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T00:38:18.257239Z","iopub.status.busy":"2022-03-25T00:38:18.256958Z","iopub.status.idle":"2022-03-25T00:38:19.405413Z","shell.execute_reply":"2022-03-25T00:38:19.404746Z","shell.execute_reply.started":"2022-03-25T00:38:18.257207Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Visualize word cloud\n","\n","list_words=''\n","for tweet in tweets['text_preprocessed']:\n","    for word in tweet:\n","        list_words += ' '+(word)\n","        \n","wordcloud = WordCloud(width = 600, height = 400, background_color = 'black', min_font_size = 10).generate(list_words)\n","fig, ax = plt.subplots(figsize = (8, 6))\n","ax.set_title('Word Cloud of Tweets Data', fontsize = 18)\n","ax.grid(False)\n","ax.imshow((wordcloud))\n","fig.tight_layout(pad=0)\n","ax.axis('off')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Positive and Negative Word Cloud"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T00:38:20.418628Z","iopub.status.busy":"2022-03-25T00:38:20.418376Z","iopub.status.idle":"2022-03-25T00:38:20.424686Z","shell.execute_reply":"2022-03-25T00:38:20.423948Z","shell.execute_reply.started":"2022-03-25T00:38:20.418602Z"},"trusted":true},"outputs":[],"source":["# Function to group all positive/negative words\n","def words_with_sentiment(text):\n","    positive_words=[]\n","    negative_words=[]\n","    for word in text:\n","        score_pos = 0\n","        score_neg = 0\n","        if (word in lexicon_positive):\n","            score_pos = lexicon_positive[word]\n","        if (word in lexicon_negative):\n","            score_neg = lexicon_negative[word]\n","        \n","        if (score_pos + score_neg > 0):\n","            positive_words.append(word)\n","        elif (score_pos + score_neg < 0):\n","            negative_words.append(word)\n","            \n","    return positive_words, negative_words"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T00:38:25.842706Z","iopub.status.busy":"2022-03-25T00:38:25.842447Z","iopub.status.idle":"2022-03-25T00:38:28.45536Z","shell.execute_reply":"2022-03-25T00:38:28.454553Z","shell.execute_reply.started":"2022-03-25T00:38:25.84268Z"},"trusted":true},"outputs":[],"source":["# Visualize positive and negative word cloud\n","\n","sentiment_words = tweets['text_preprocessed'].apply(words_with_sentiment)\n","sentiment_words = list(zip(*sentiment_words))\n","positive_words = sentiment_words[0]\n","negative_words = sentiment_words[1]\n","\n","fig, ax = plt.subplots(1, 2,figsize = (12, 10))\n","list_words_postive=''\n","for row_word in positive_words:\n","    for word in row_word:\n","        list_words_postive += ' '+(word)\n","wordcloud_positive = WordCloud(width = 800, height = 600, background_color = 'black', colormap = 'Greens'\n","                               , min_font_size = 10).generate(list_words_postive)\n","ax[0].set_title('Word Cloud of Positive Words on Tweets Data \\n (based on Indonesia Sentiment Lexicon)', fontsize = 14)\n","ax[0].grid(False)\n","ax[0].imshow((wordcloud_positive))\n","fig.tight_layout(pad=0)\n","ax[0].axis('off')\n","\n","list_words_negative=''\n","for row_word in negative_words:\n","    for word in row_word:\n","        list_words_negative += ' '+(word)\n","wordcloud_negative = WordCloud(width = 800, height = 600, background_color = 'black', colormap = 'Reds'\n","                               , min_font_size = 10).generate(list_words_negative)\n","ax[1].set_title('Word Cloud of Negative Words on Tweets Data \\n (based on Indonesia Sentiment Lexicon)', fontsize = 14)\n","ax[1].grid(False)\n","ax[1].imshow((wordcloud_negative))\n","fig.tight_layout(pad=0)\n","ax[1].axis('off')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Sentiment Analysis Using LSTM"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocessing Text Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T00:38:44.102562Z","iopub.status.busy":"2022-03-25T00:38:44.101829Z","iopub.status.idle":"2022-03-25T00:38:44.23557Z","shell.execute_reply":"2022-03-25T00:38:44.23482Z","shell.execute_reply.started":"2022-03-25T00:38:44.102525Z"},"trusted":true},"outputs":[],"source":["# Make text preprocessed (tokenized) to untokenized with toSentence Function\n","X = tweets['text_preprocessed'].apply(toSentence) \n","max_features = 5000\n","\n","# Tokenize text with specific maximum number of words to keep, based on word frequency\n","tokenizer = Tokenizer(num_words=max_features, split=' ')\n","tokenizer.fit_on_texts(X.values)\n","X = tokenizer.texts_to_sequences(X.values)\n","X = pad_sequences(X)\n","X.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T00:38:51.48825Z","iopub.status.busy":"2022-03-25T00:38:51.487684Z","iopub.status.idle":"2022-03-25T00:38:51.498713Z","shell.execute_reply":"2022-03-25T00:38:51.497847Z","shell.execute_reply.started":"2022-03-25T00:38:51.488204Z"},"trusted":true},"outputs":[],"source":["# Encode target data into numerical values\n","polarity_encode = {'negative' : 0, 'neutral' : 1, 'positive' : 2}\n","y = tweets['polarity'].map(polarity_encode).values\n","\n","# Split the data (with composition data train 80%, data test 20%)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n","print(X_train.shape, y_train.shape)\n","print(X_test.shape, y_test.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Model LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T00:38:58.978558Z","iopub.status.busy":"2022-03-25T00:38:58.978087Z","iopub.status.idle":"2022-03-25T00:38:58.985001Z","shell.execute_reply":"2022-03-25T00:38:58.984183Z","shell.execute_reply.started":"2022-03-25T00:38:58.97852Z"},"trusted":true},"outputs":[],"source":["# Create model function with default hyperparameter values\n","\n","def create_model(embed_dim = 16, hidden_unit = 16, dropout_rate = 0.2, optimizers = Adam, learning_rate = 0.001):\n","    model = Sequential()\n","    model.add(Embedding(input_dim = max_features, output_dim = embed_dim, input_length = X_train.shape[1]))\n","    model.add(LSTM(units = hidden_unit, activation = 'tanh'))\n","    model.add(Dropout(dropout_rate))\n","    model.add(Dense(units = 3, activation = 'softmax'))\n","    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = optimizers(learning_rate = learning_rate), metrics = ['accuracy'])\n","    print(model.summary())\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T00:39:03.930399Z","iopub.status.busy":"2022-03-25T00:39:03.929818Z","iopub.status.idle":"2022-03-25T00:42:30.338533Z","shell.execute_reply":"2022-03-25T00:42:30.337759Z","shell.execute_reply.started":"2022-03-25T00:39:03.930359Z"},"trusted":true},"outputs":[],"source":["# From results above, we know the best hyperparameter for this model is :\n","# {'batch_size': 128, 'dropout_rate': 0.2, 'embed_dim': 32, 'epochs': 10, 'hidden_unit': 16, 'learning_rate': 0.001, 'optimizers': <class 'keras.optimizers.RMSprop'>}\n","\n","# Create the model with the best hyperparameter which has been determined\n","model = KerasClassifier(build_fn = create_model,\n","                        # Model Parameters\n","                        dropout_rate = 0.2,\n","                        embed_dim = 32,\n","                        hidden_unit = 16,\n","                        optimizers = RMSprop,\n","                        learning_rate = 0.001,\n","                   \n","                        # Fit Parameters\n","                        epochs=1000, \n","                        batch_size=128,\n","                        # Initiate validation data, which is 10% data from data train. It's used for evaluation model\n","                        validation_split = 0.1)\n","                         \n","\n","model_prediction = model.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T00:42:30.588466Z","iopub.status.busy":"2022-03-25T00:42:30.588037Z","iopub.status.idle":"2022-03-25T00:42:30.818632Z","shell.execute_reply":"2022-03-25T00:42:30.817973Z","shell.execute_reply.started":"2022-03-25T00:42:30.588427Z"},"trusted":true},"outputs":[],"source":["# Visualization model accuracy (train and val accuracy)\n","\n","fig, ax = plt.subplots(figsize = (10, 4))\n","ax.plot(model_prediction.history['accuracy'], label = 'train accuracy')\n","ax.plot(model_prediction.history['val_accuracy'], label = 'val accuracy')\n","ax.set_title('Model Accuracy')\n","ax.set_xlabel('Epoch')\n","ax.set_ylabel('Accuracy')\n","ax.legend(loc = 'upper left')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T00:42:45.537206Z","iopub.status.busy":"2022-03-25T00:42:45.536869Z","iopub.status.idle":"2022-03-25T00:42:46.440782Z","shell.execute_reply":"2022-03-25T00:42:46.43995Z","shell.execute_reply.started":"2022-03-25T00:42:45.537135Z"},"trusted":true},"outputs":[],"source":["# Predict sentiment on data test by using model has been created, and then visualize a confusion matrix\n","\n","\n","y_pred = model.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print('Model Accuracy on Test Data:', accuracy)\n","confusion_matrix(y_test, y_pred)\n","\n","fig, ax = plt.subplots(figsize = (8,6))\n","sns.heatmap(confusion_matrix(y_true = y_test, y_pred = y_pred), fmt = 'g', annot = True)\n","ax.xaxis.set_label_position('top')\n","ax.xaxis.set_ticks_position('top')\n","ax.set_xlabel('Prediction', fontsize = 14)\n","ax.set_xticklabels(['negative (0)', 'neutral (1)', 'positive (2)'])\n","ax.set_ylabel('Actual', fontsize = 14)\n","ax.set_yticklabels(['negative (0)', 'neutral (1)', 'positive (2)'])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T00:42:51.886959Z","iopub.status.busy":"2022-03-25T00:42:51.886221Z","iopub.status.idle":"2022-03-25T00:42:51.908391Z","shell.execute_reply":"2022-03-25T00:42:51.907735Z","shell.execute_reply.started":"2022-03-25T00:42:51.88692Z"},"trusted":true},"outputs":[],"source":["# Results from prediction sentiment on data test\n","text_clean = tweets['text_clean']\n","text_train, text_test = train_test_split(text_clean, test_size = 0.2, random_state = 0)\n","result_test = pd.DataFrame(data = zip(text_test, y_pred), columns = ['text', 'polarity'])\n","polarity_decode = {0 : 'Negative', 1 : 'Neutral', 2 : 'Positive'}\n","result_test['polarity'] = result_test['polarity'].map(polarity_decode)\n","pd.set_option('max_colwidth', 300)\n","result_test"]},{"cell_type":"markdown","metadata":{},"source":["## Predict with Other Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T00:44:20.368008Z","iopub.status.busy":"2022-03-25T00:44:20.367475Z","iopub.status.idle":"2022-03-25T00:44:20.401012Z","shell.execute_reply":"2022-03-25T00:44:20.400232Z","shell.execute_reply.started":"2022-03-25T00:44:20.36797Z"},"trusted":true},"outputs":[],"source":["# Initializing and preprocessing new text data\n","otherData = pd.DataFrame()\n","otherData['text'] = ['italy harus menang',\n","                     'italy harus kalah',\n","                    \n","                    ]\n","\n","otherData['text_clean'] = otherData['text'].apply(cleaningText)\n","otherData['text_clean'] = otherData['text_clean'].apply(casefoldingText)\n","otherData.drop(['text'], axis = 1, inplace = True)\n","\n","otherData['text_preprocessed'] = otherData['text_clean'].apply(tokenizingText)\n","otherData['text_preprocessed'] = otherData['text_preprocessed'].apply(filteringText)\n","otherData['text_preprocessed'] = otherData['text_preprocessed'].apply(stemmingText)\n","otherData"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T00:44:22.791932Z","iopub.status.busy":"2022-03-25T00:44:22.791361Z","iopub.status.idle":"2022-03-25T00:44:22.799591Z","shell.execute_reply":"2022-03-25T00:44:22.798634Z","shell.execute_reply.started":"2022-03-25T00:44:22.791895Z"},"trusted":true},"outputs":[],"source":["# Preprocessing text data\n","\n","# Make text preprocessed (tokenized) to untokenized with toSentence Function\n","X_otherData = otherData['text_preprocessed'].apply(toSentence)\n","X_otherData = tokenizer.texts_to_sequences(X_otherData.values)\n","X_otherData = pad_sequences(X_otherData, maxlen = X.shape[1])\n","X_otherData"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T00:44:25.345304Z","iopub.status.busy":"2022-03-25T00:44:25.344921Z","iopub.status.idle":"2022-03-25T00:44:25.395676Z","shell.execute_reply":"2022-03-25T00:44:25.395007Z","shell.execute_reply.started":"2022-03-25T00:44:25.345266Z"},"trusted":true},"outputs":[],"source":["# Results from prediction sentiment on text data\n","\n","y_pred_otherData = model.predict(X_otherData)\n","otherData['Result Prediction'] = y_pred_otherData\n","\n","polarity_decode = {0 : 'Negative', 1 : 'Neutral', 2 : 'Positive'}\n","otherData['Result Prediction'] = otherData['Result Prediction'].map(polarity_decode)\n","otherData"]}],"metadata":{"interpreter":{"hash":"cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"},"kernelspec":{"display_name":"Python 3.9.7 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":4}
